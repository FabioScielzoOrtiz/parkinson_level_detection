{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inner Evaluation 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explore an approach based on sequential data (using MFCC time-varying features), with Recurrent Neural Networks.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import polars as pl\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, r\"C:\\Users\\fscielzo\\Documents\\Packages\\PyAudio_Package_Private\")\n",
    "from PyAudio.preprocessing import get_X_tensor_audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, r'C:\\Users\\fscielzo\\Documents\\Packages\\PyML_Package_Private')\n",
    "from PyML.evaluation import SimpleEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, r'C:\\Users\\fscielzo\\Documents\\Packages\\PyDL_Package_Private')\n",
    "from PyDL.models import RNN\n",
    "from PyDL.preprocessing import TensorStandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = NeuralNetClassifier(\n",
    "    module=RNN(input_dim=10, output_dim=2, num_layers=3, hidden_size=128),\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.001,\n",
    "    batch_size=50,\n",
    "    max_epochs=15,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data definition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we define the data to be used. Specifically we define the response variable and a set of predictors matrices to be used as different alternatives, each one associate to a combination of features extraction methods and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list_name = r'C:\\Users\\fscielzo\\Documents\\DataScience-GitHub\\Audio Analysis\\Parkinson_Severity_Classification\\Data\\Files_List.txt'\n",
    "files_df = pl.read_csv(files_list_name, separator='\\t', has_header=False, new_columns=['path', 'level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables for feature extraction\n",
    "fs = 16000 # Sampling frequency\n",
    "wst = 0.032 # Window size (seconds)\n",
    "fpt = 0.008 # Frame period (seconds)\n",
    "nfft = int(np.ceil(wst*fs)) # Window size (samples)\n",
    "fp = int(np.ceil(fpt*fs)) # Frame period (samples)\n",
    "nbands = 40 # Number of filters in the filterbank\n",
    "ncomp = 20 # Number of MFCC components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the response and the tensor with the time-varying features extracted with the MFCC method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = files_df['level'].to_numpy()\n",
    "\n",
    "X_MFCC_tensor = get_X_tensor_audio_features(paths=files_df['path'], method='MFCC', sr=fs, n_fft=nfft, hop_length=fp, n_mels=nbands, n_mfcc=ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chroma_tensor = get_X_tensor_audio_features(paths=files_df['path'], method='chroma', sr=fs, n_fft=nfft, hop_length=fp, n_mels=nbands, n_mfcc=ncomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outer validation method: train-test split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data (response and predictors) in two partitions, the training and the testing one. The training partition will be used in the inner evaluation for selecting the best approach to predict the PD level, and the test one will only be used at the very end for making an estimation of the future performance of the best approach, that is, and estimation of how this approach will classify the level of PD of new patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MFCC_tensor_train, X_MFCC_tensor_test, Y_train, Y_test = train_test_split(X_MFCC_tensor, Y, test_size=0.25, random_state=123, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 20, 4403)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_MFCC_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 20, 4403)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_MFCC_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 20, 4403)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_MFCC_tensor_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardizing the data since it seems to work well with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for standardization (from 3D to 2D)\n",
    "n_samples, n_mfcc, max_length = X_MFCC_tensor_train.shape\n",
    "X_MFCC_tensor_train_flatten = X_MFCC_tensor_train.reshape(-1, n_mfcc * max_length)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_MFCC_train_standardized = scaler.fit_transform(X_MFCC_tensor_train_flatten)\n",
    "\n",
    "# Reshape back to 3D\n",
    "X_MFCC_tensor_train = X_MFCC_train_standardized.reshape(n_samples, n_mfcc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for standardization (from 3D to 2D)\n",
    "n_samples, n_mfcc, max_length = X_MFCC_tensor_test.shape\n",
    "X_MFCC_tensor_test_flatten = X_MFCC_tensor_test.reshape(-1, n_mfcc * max_length)\n",
    "\n",
    "# Standardize the data\n",
    "X_MFCC_test_standardized = scaler.transform(X_MFCC_tensor_test_flatten)\n",
    "\n",
    "# Reshape back to 3D\n",
    "X_MFCC_tensor_test = X_MFCC_test_standardized.reshape(n_samples, n_mfcc, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better approach to do this without falling in data leakage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.77925549,  0.75966389,  0.75801119, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 0.49572165,  0.11072004, -0.31598378, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.34147712,  1.38633399,  1.4529877 , ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.48452161, -0.07294603,  0.47874218, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.382128  ,  1.93450536,  2.12793082, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.97325322, -1.423122  , -1.50599919, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-1.09754581, -1.2406114 , -1.43178652, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-0.21227887, -0.53582309, -1.00587868, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.01043724, -0.08198521, -0.06441753, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.63225567,  0.53115129,  0.74958524, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.47306939,  0.46868749,  0.82995921, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.49799736,  1.56677656,  1.18140685, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-0.93716879, -0.92827138, -0.89666019, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-0.39703831, -0.31946003, -0.37899106, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.35987158, -0.70249106, -0.93452423, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [-0.28148851, -0.39495589,  0.04978402, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.34802631, -2.12577281, -1.47394572, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.49579407, -1.6952296 , -1.53697988, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.6565104 ,  0.65331194,  0.70792749, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 0.72916882,  0.81260307,  0.70276269, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.70178372,  0.89056889,  0.78858701, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [-0.40537788, -0.64057784, -0.9321527 , ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.9375777 , -0.4679151 ,  0.41955871, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.72704588, -0.15770425,  0.56146658, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-1.26680811, -1.19761807, -1.21938432, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-0.86848324, -0.76134084, -0.62641248, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.28175129, -0.54700239, -0.58084685, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [-0.38528358,  0.3547839 ,  0.73461061, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 2.46115109,  1.7585346 ,  1.48140808, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.38349091,  0.54929556, -0.42187174, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[ 0.04556678, -0.04351323, -0.12983973, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 1.99804549,  1.83888045,  1.60835686, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 2.35297563,  2.29635284,  2.03319404, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.30947655,  0.43012554,  0.22527788, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.12866233,  0.34554382,  0.82022089, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-1.43149724, -1.59260321, -1.39095793, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_MFCC_tensor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 20, 4403)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_MFCC_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.77925549,  0.75966389,  0.75801119, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 0.49572165,  0.11072004, -0.31598378, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.34147712,  1.38633399,  1.4529877 , ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.48452161, -0.07294603,  0.47874218, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.382128  ,  1.93450536,  2.12793082, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.97325322, -1.423122  , -1.50599919, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-1.09754581, -1.2406114 , -1.43178652, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-0.21227887, -0.53582309, -1.00587868, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.01043724, -0.08198521, -0.06441753, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.63225567,  0.53115129,  0.74958524, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.47306939,  0.46868749,  0.82995921, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.49799736,  1.56677656,  1.18140685, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-0.93716879, -0.92827138, -0.89666019, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-0.39703831, -0.31946003, -0.37899106, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.35987158, -0.70249106, -0.93452423, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [-0.28148851, -0.39495589,  0.04978402, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.34802631, -2.12577281, -1.47394572, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.49579407, -1.6952296 , -1.53697988, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.6565104 ,  0.65331194,  0.70792749, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 0.72916882,  0.81260307,  0.70276269, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.70178372,  0.89056889,  0.78858701, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [-0.40537788, -0.64057784, -0.9321527 , ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.9375777 , -0.4679151 ,  0.41955871, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.72704588, -0.15770425,  0.56146658, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-1.26680811, -1.19761807, -1.21938432, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-0.86848324, -0.76134084, -0.62641248, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.28175129, -0.54700239, -0.58084685, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [-0.38528358,  0.3547839 ,  0.73461061, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 2.46115109,  1.7585346 ,  1.48140808, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.38349091,  0.54929556, -0.42187174, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[ 0.04556678, -0.04351323, -0.12983973, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 1.99804549,  1.83888045,  1.60835686, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 2.35297563,  2.29635284,  2.03319404, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.30947655,  0.43012554,  0.22527788, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.12866233,  0.34554382,  0.82022089, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-1.43149724, -1.59260321, -1.39095793, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = TensorStandardScaler(apply=True)\n",
    "scaler.fit(X_MFCC_tensor_train)\n",
    "scaler.transform(X_MFCC_tensor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 20, 4403)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_MFCC_tensor_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.1088349 , -1.21068496, -1.24170116, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-1.29952919, -1.45907204, -1.43475645, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.07323975, -0.41990087, -0.55769708, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.74406594,  0.77746824,  0.67277322, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.69785958,  0.69918349,  0.65714235, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.57196627,  0.64494054,  0.76531219, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-0.3483037 , -0.15471678,  0.15473919, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 0.66910327,  0.9586072 ,  1.04969775, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-1.33066569, -1.04541998, -0.74294924, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 2.24923983,  2.19150319,  1.54300361, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-1.78269042, -0.12646651, -0.44859062, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-2.07612607,  0.7965252 ,  0.31931094, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-1.03763687, -1.0695463 , -1.02396231, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-1.32669176, -1.20835791, -0.94714662, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.32077486, -0.16320353,  0.13569455, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.8763195 , -0.01483926, -0.5642226 , ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.33603545, -0.5300002 , -0.87023331, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.17797754, -0.50627413, -0.62680684, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.79789592,  0.6718777 ,  0.33046552, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 0.73263119,  0.99082343,  1.51836759, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.90628487,  1.27901072,  2.08666589, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.24868375,  0.24592557,  0.39300569, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.84737753,  0.36539538, -0.31156388, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.68994957,  1.07338474,  1.22594029, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[ 1.59412017,  1.53726977,  1.32176695, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [ 0.44501062,  0.12176085, -0.75543876, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.5138407 , -0.584392  ,  0.04589857, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 1.73706153,  1.46862996,  3.56796765, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 1.13340098,  1.77850333,  1.6402638 , ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.24298456,  0.29429363, -1.11233773, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]],\n",
       "\n",
       "       [[-1.17565817, -1.22614176, -1.23409303, ...,  0.07474351,\n",
       "          0.07474351,  0.07474351],\n",
       "        [-1.48596274, -1.36792995, -1.26105226, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [-0.67358414, -0.27077418, -0.29346544, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        ...,\n",
       "        [ 0.2830349 ,  0.62647133,  0.50570222, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.31699058,  0.5937816 ,  0.49041113, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351],\n",
       "        [ 0.19708623,  0.36830872,  0.51281274, ..., -0.07474351,\n",
       "         -0.07474351, -0.07474351]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_MFCC_tensor_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting to tensor `PyTroch` data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MFCC_tensor = torch.tensor(X_MFCC_tensor, dtype=torch.float32)\n",
    "X_MFCC_tensor_train = torch.tensor(X_MFCC_tensor_train, dtype=torch.float32)\n",
    "X_MFCC_tensor_test = torch.tensor(X_MFCC_tensor_test, dtype=torch.float32)\n",
    "\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Applying Inner Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to apply the round four of the inner evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inner validation method: KFold Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the validation method to be used in the inner evaluation, that will be Stratified KFold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define dictionaries to save important results that will be gathered in the inner evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_score, best_params, inner_results = {}, {}, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grids for HPO** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid for RNN (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_RNN(trial, input_dim, output_dim):\n",
    "\n",
    "    param_grid = ({\n",
    "        'module__input_dim': trial.suggest_categorical('module__input_dim', [input_dim]),\n",
    "        'module__output_dim': trial.suggest_categorical('module__output_dim', [output_dim]),\n",
    "        'module__num_layers': trial.suggest_int('module__num_layers', 1, 10),\n",
    "        'module__hidden_size': trial.suggest_categorical('module__hidden_size', [50, 70, 100, 120, 150, 175, 200, 250]),\n",
    "        'module__dropout_rate': trial.suggest_float('module__dropout_rate', 0.05, 0.95, log=True),\n",
    "        'lr': trial.suggest_float('lr', 0.0001, 0.01, log=True),\n",
    "        'max_epochs': trial.suggest_categorical('max_epochs', [5, 7, 10, 15, 20, 25, 30, 40, 50, 75, 100]),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [15, 30, 50, 70, 100])\n",
    "    })\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HPO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying HPO over Recurrent Neural Networks using the MFCC sequencies of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPO for RNN (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-16 17:55:50,367] A new study created in memory with name: no-name-5987d063-91d8-4e87-bb8a-845f53459244\n"
     ]
    }
   ],
   "source": [
    "model = 'RNN'\n",
    "\n",
    "input_dim = X_MFCC_tensor_train.shape[2]\n",
    "output_dim = len(np.unique(Y_train))\n",
    "\n",
    "simple_eval = SimpleEvaluation(estimator=RNN_model, param_grid=param_grid_RNN, \n",
    "                inner=inner, search_method='optuna', scoring='balanced_accuracy', direction='maximize', \n",
    "                n_trials=5, random_state=123, \n",
    "                framework='PyTorch', \n",
    "                input_dim=input_dim,\n",
    "                output_dim=output_dim)\n",
    "\n",
    "simple_eval.fit(X=X_MFCC_tensor_train, y=Y_train_tensor.long())\n",
    "inner_score[model] = simple_eval.inner_score\n",
    "best_params[model]= simple_eval.inner_best_params\n",
    "inner_results[model] = simple_eval.inner_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('results/best_params_4', 'wb') as file:\n",
    "    pickle.dump(best_params, file)\n",
    "\n",
    "with open('results/inner_scores_4', 'wb') as file:\n",
    "    pickle.dump(inner_score, file)\n",
    "\n",
    "with open('results/inner_results_4', 'wb') as file:\n",
    "    pickle.dump(inner_results, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/best_params_4', 'rb') as file:\n",
    "        best_params = pickle.load(file)\n",
    "\n",
    "with open(f'results/inner_scores_4', 'rb') as file:\n",
    "        inner_score = pickle.load(file)\n",
    "\n",
    "with open(f'results/inner_results_4', 'rb') as file:\n",
    "        inner_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Selecting the best pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we don't have several alternatives to compare, since we have only one, a RNN using sequential features extracted with MFCC method.\n",
    "\n",
    "The inner obtained balanced accuracy  for the optimal RNN is quite poor, which could be due to a bad specification of the model or the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RNN': 0.4431818181818182}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
